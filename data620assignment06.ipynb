{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA 620 - Assignment 6\n",
    "\n",
    "Jeremy OBrien, Mael Illien, Vanita Thompson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* It can be useful to be able to classify new \"test\" documents using already classified \"training\" documents. A common example is using a corpus of labeled spam and ham (non-spam) e-mails to predict whether or not a new document is spam. Here is one example of such data:  UCI Machine Learning Repository: Spambase Data Set (http://archive.ics.uci.edu/ml/datasets/Spambase)\n",
    "* For this project, you can either use the above dataset to predict the class of new documents (either withheld from the training dataset or from another source such as your own spam folder).\n",
    "* For more adventurous students, you are welcome (encouraged!) to come up a different set of documents (including scraped web pages!?) that have already been classified (e.g. tagged), then analyze these documents to predict how new documents should be classified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, we explore binary classification from the perspective of 'spam' and 'non-spam' (also referred to as 'ham').\n",
    "\n",
    "The [spamassassin corpus](https://spamassassin.apache.org/old/publiccorpus/) contains individual raw email files which are extracted and processed to form a unified corpus. From this corpus, we split the data into training and test sets, then develop a variety of models to identify the best approach to spam email classification. \n",
    "\n",
    "The procedure is as follows:\n",
    "   - Extract emails from raw files\n",
    "   - Process email content, ignoring headers and isolating the body of the emails\n",
    "   - Apply NLP methods from NLTK and Sklearn to tokenize the email content and generate features\n",
    "   - Develop models\n",
    "   - Compare classifier performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from nltk import PorterStemmer\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import & Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ham and spam emails are stored in individual files. The `get_emails` function below extracts the content from the file and returns a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read individual files from current directory and return the content in a list\n",
    "def get_emails(path):\n",
    "    emails = []\n",
    "    files = [path + f for f in listdir(path) if f != 'cmds']\n",
    "\n",
    "    for file in files:\n",
    "        with open(file, encoding=\"latin-1\") as f:\n",
    "            email = f.read()\n",
    "            if len(email) != 0:\n",
    "                emails.append(email) \n",
    "    return emails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's apparent that the ham and spam corpora are not balanced, so we sample the ham corpus to even out the size in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of emails in easy_ham corpus: 2500\n",
      "Number of emails in spam corpus: 500\n"
     ]
    }
   ],
   "source": [
    "easy_ham = get_emails('./easy_ham/')\n",
    "spam = get_emails('./spam/')\n",
    "\n",
    "print('Number of emails in {} corpus: {}'.format('easy_ham', len(easy_ham)))\n",
    "print('Number of emails in {} corpus: {}'.format('spam', len(spam)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example of the email format, which begins with a number of headers followed by the email body. \n",
    "\n",
    "Our analysis is focused on email body content, and the function `get_email_body` is used to extract it. While it is possible that header information may aid with classification, this is not in the scope of our present investigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From rssfeeds@jmason.org  Thu Sep 26 16:43:26 2002\n",
      "Return-Path: <rssfeeds@spamassassin.taint.org>\n",
      "Delivered-To: yyyy@localhost.spamassassin.taint.org\n",
      "Received: from localhost (jalapeno [127.0.0.1])\n",
      "\tby jmason.org (Postfix) with ESMTP id E534F16F03\n",
      "\tfor <jm@localhost>; Thu, 26 Sep 2002 16:42:33 +0100 (IST)\n",
      "Received: from jalapeno [127.0.0.1]\n",
      "\tby localhost with IMAP (fetchmail-5.9.0)\n",
      "\tfor jm@localhost (single-drop); Thu, 26 Sep 2002 16:42:33 +0100 (IST)\n",
      "Received: from dogma.slashnull.org (localhost [127.0.0.1]) by\n",
      "    dogma.slashnull.org (8.11.6/8.11.6) with ESMTP id g8QFTVg24692 for\n",
      "    <jm@jmason.org>; Thu, 26 Sep 2002 16:29:31 +0100\n",
      "Message-Id: <200209261529.g8QFTVg24692@dogma.slashnull.org>\n",
      "To: yyyy@spamassassin.taint.org\n",
      "From: guardian <rssfeeds@spamassassin.taint.org>\n",
      "Subject: Play by Play: Effective Memory Management\n",
      "Date: Thu, 26 Sep 2002 15:29:31 -0000\n",
      "Content-Type: text/plain; encoding=utf-8\n",
      "\n",
      "URL: http://www.newsisfree.com/click/-6,6503039,159/\n",
      "Date: 2002-08-03T08:11:17+01:00\n",
      "\n",
      "Back when 64KB was more memory than any computer would ever need, there was a \n",
      "time when memory managers didnt exist. But gradually, new computer systems \n",
      "came out with larger amounts of memory and designers discovered ways to eat up \n",
      "RAM faster than any system could dish it out. This discussion is based on \n",
      "Tiburon's experiences in writing and rewriting the memory manager for Madden \n",
      "NFL 97 to Madden NFL 2002.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(easy_ham[2002])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract only the body of the emails, ignoring all the headers\n",
    "def get_email_body(email):\n",
    "    # Looking for the last occurence of Date: Sat, 02 Feb 2002 11:20:17 +1300\\n\n",
    "    iter = re.finditer(r\"Date: .*\\n\", email)\n",
    "    # Otherwise look for repeated \\n\\n patterm\n",
    "\n",
    "    indices = [m.span() for m in iter]\n",
    "    body_start = indices[-1][1]\n",
    "    body = email[body_start:].replace(\"\\n\", \"\")\n",
    "\n",
    "    return body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example of just the body content for an email."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Back when 64KB was more memory than any computer would ever need, there was a time when memory managers didnt exist. But gradually, new computer systems came out with larger amounts of memory and designers discovered ways to eat up RAM faster than any system could dish it out. This discussion is based on Tiburon's experiences in writing and rewriting the memory manager for Madden NFL 97 to Madden NFL 2002.\n"
     ]
    }
   ],
   "source": [
    "print(get_email_body(easy_ham[2002]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply the `get_email_body` function to the emails to assemble the corpus. We balance the two classes by combining the spam emails with 500 emails sampled rom the total. The known labels of 'ham:0' and 'spam:1' are also assigned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1000 emails in this corpus.\n"
     ]
    }
   ],
   "source": [
    "# Assemble the corpus by combining the spam emails with 500 emails sampled from the \n",
    "# ham emails to balance the dataset and assign the known labels ham: 0, spam:1\n",
    "random.seed(620)\n",
    "labeled_emails = ([(get_email_body(em), '0') for em in random.choices(easy_ham, k=500)] + \n",
    "                    [(get_email_body(em), '1') for em in spam])\n",
    "\n",
    "print('There are {} emails in this corpus.'.format(len(labeled_emails)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLP approaches we can use to process text and engineer features include tokenizing, case normalization, symbol removal, stopword removal, stemming, and lemmatization.  There approaches are not exclusive and many could be combined, for example:\n",
    "\n",
    "- Case normalization or no; and,\n",
    "- Noun only or verb only or both; and,\n",
    "- Symbol removal or no; and,\n",
    "- Stopword removal or no; and,\n",
    "- Stemming or lemmatization or neither\n",
    "\n",
    "We trial a number of these approaches individually on a sample email, and compose a function `process_email_body`with parameter that allow for close control over the processing.  \n",
    "\n",
    "Unfortunately, running the function is prohibitively expensive to compute, and troubleshooting doesn't improve this in a timely fashion, so we use the built-in pre-processor in the `sklearn` library for this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'    From:        Chris Garrigues <cwg-dated-1030377287.06fa6d@DeepEddy.Com>    Message-ID:  <1029945287.4797.TMDA@deepeddy.vircio.com>  | I can\\'t reproduce this error.For me it is very repeatable... (like every time, without fail).This is the debug log of the pick happening ...18:19:03 Pick_It {exec pick +inbox -list -lbrace -lbrace -subject ftp -rbrace -rbrace} {4852-4852 -sequence mercury}18:19:03 exec pick +inbox -list -lbrace -lbrace -subject ftp -rbrace -rbrace 4852-4852 -sequence mercury18:19:04 Ftoc_PickMsgs {{1 hit}}18:19:04 Marking 1 hits18:19:04 tkerror: syntax error in expression \"int ...Note, if I run the pick command by hand ...delta$ pick +inbox -list -lbrace -lbrace -subject ftp -rbrace -rbrace  4852-4852 -sequence mercury1 hitThat\\'s where the \"1 hit\" comes from (obviously).  The version of nmh I\\'musing is ...delta$ pick -versionpick -- nmh-1.0.4 [compiled on fuchsia.cs.mu.OZ.AU at Sun Mar 17 14:55:56 ICT 2002]And the relevant part of my .mh_profile ...delta$ mhparam pick-seq sel -listSince the pick command works, the sequence (actually, both of them, theone that\\'s explicit on the command line, from the search popup, and theone that comes from .mh_profile) do get created.kreps: this is still using the version of the code form a day ago, I haven\\'tbeen able to reach the cvs repository today (local routing issue I think)._______________________________________________Exmh-workers mailing listExmh-workers@redhat.comhttps://listman.redhat.com/mailman/listinfo/exmh-workers'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_email_body(easy_ham[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['From', ':', 'Chris', 'Garrigues', '<', 'cwg-dated-1030377287.06fa6d', '@', 'DeepEddy.Com', '>', 'Message-ID']\n"
     ]
    }
   ],
   "source": [
    "# Tokenize\n",
    "tokens = word_tokenize(get_email_body(easy_ham[0]))\n",
    "print(tokens[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136\n",
      "['from', 'chris', 'garrigues', 'i', 'ca', 'reproduce', 'this', 'me', 'it', 'is']\n"
     ]
    }
   ],
   "source": [
    "# Normalize\n",
    "word_tokens = [w.lower() for w in tokens if w.isalpha()] \n",
    "print(len(word_tokens))\n",
    "print(word_tokens[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n",
      "['chris', 'garrigues', 'ca', 'reproduce', 'repeatable', 'like', 'every', 'time', 'without', 'fail']\n"
     ]
    }
   ],
   "source": [
    "# Stopword removal \n",
    "stop_words = stopwords.words('english')\n",
    "filtered_words = [w for w in word_tokens if not w in stop_words]\n",
    "print(len(filtered_words))\n",
    "print(filtered_words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chri', 'garrigu', 'ca', 'reproduc', 'repeat', 'like', 'everi', 'time', 'without', 'fail', 'debug', 'log', 'pick', 'happen', 'exec', 'pick', 'ftp', 'mercuri', 'exec', 'pick']\n"
     ]
    }
   ],
   "source": [
    "# Stemming\n",
    "porter = PorterStemmer()\n",
    "stemmed_words = [porter.stem(t) for t in filtered_words]\n",
    "print(stemmed_words[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual pre-processing function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As described above, the function `process_email_body` can be applied to each email in order to turn the content of the emails into useable features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process email: tokenize, remove non-alpha characters, remove stop words, stem, lemmatize\n",
    "# and return a list of tokens\n",
    "def process_email_body(email, alpha=True, rm_stopwords=True, stem=True, lemma=False):\n",
    "    tokens = word_tokenize(email)\n",
    "    if alpha: tokens = [w.lower() for w in tokens if w.isalpha()] \n",
    "    if rm_stopwords: \n",
    "        stop_words = stopwords.words('english')\n",
    "        tokens = [w for w in tokens if not w in stop_words]\n",
    "    if stem:\n",
    "        porter = PorterStemmer()\n",
    "        tokens = [porter.stem(t) for t in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chri', 'garrigu', 'ca', 'reproduc', 'repeat', 'like', 'everi', 'time', 'without', 'fail', 'debug', 'log', 'pick', 'happen', 'exec', 'pick', 'ftp', 'mercuri', 'exec', 'pick', 'ftp', 'hit', 'mark', 'tkerror', 'syntax', 'error', 'express', 'int', 'note', 'run', 'pick', 'command', 'hand', 'delta', 'pick', 'ftp', 'hitthat', 'hit', 'come', 'obvious', 'version', 'nmh', 'delta', 'pick', 'compil', 'sun', 'mar', 'ict', 'relev', 'part', 'delta', 'mhparam', 'sel', 'pick', 'command', 'work', 'sequenc', 'actual', 'theon', 'explicit', 'command', 'line', 'search', 'popup', 'theon', 'come', 'get', 'still', 'use', 'version', 'code', 'form', 'day', 'ago', 'abl', 'reach', 'cv', 'repositori', 'today', 'local', 'rout', 'issu', 'think', 'mail']\n"
     ]
    }
   ],
   "source": [
    "# Example above revisited using the function\n",
    "print(process_email_body(get_email_body(easy_ham[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As troubleshooting did not speed the very slow computation of this function in a timely fashion, we turned to the built-in sklearn pre-processor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing using sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sklearn `TfidfVectorizer` object allows us to apply similar processing steps to those outlined above. We implement it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refer to https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "\n",
    "emails = [email for (email, label) in labeled_emails] # X = emails features (see below)\n",
    "y = [label for (email, label) in labeled_emails] # y = labels\n",
    "\n",
    "vectorizer = TfidfVectorizer(lowercase=True, stop_words='english', token_pattern = r'[a-zA-Z]+', max_features=5000)\n",
    "\n",
    "X = vectorizer.fit_transform(emails)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring some of the features returned by the vectorizer, we find english words such as 'address' or 'advertising' but also a number of html tags such as 'cellpadding' or 'bgcolor' which are often typical of spam emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['aa', 'aaa', 'aad', 'aadhv', 'ab', 'abc', 'abdc', 'abidjan', 'ability', 'able', 'abmv', 'aboriginal', 'aboutthe', 'abroad', 'absmiddle', 'absolute', 'absolutely', 'abuse', 'ac', 'acb', 'acceleration', 'accept', 'acceptance', 'accepted', 'access', 'according', 'account', 'accounting', 'accounts', 'ace', 'achieve', 'acknowledge', 'acknowledged', 'acquire', 'acquisition', 'act', 'acting', 'action', 'actions', 'active', 'actively', 'activities', 'activity', 'acts', 'actual', 'actually', 'ad', 'adam', 'adapt', 'adb', 'adclick', 'add', 'added', 'adding', 'addition', 'additional', 'addr', 'address', 'addresses', 'adfarm', 'adfree', 'adman', 'admanmail', 'admin', 'administration', 'ads', 'adult', 'adv', 'advance', 'advanced', 'advantage', 'adversaries', 'advertise', 'advertised', 'advertisement', 'advertisers', 'advertising', 'advice', 'advicehttp', 'advised', 'adybn', 'ae', 'af', 'aff', 'affairs', 'affid', 'affiliate', 'affiliated', 'affiliates', 'affordable', 'afft', 'afghanistan', 'afraid', 'africa', 'african', 'ag', 'age', 'agencies', 'agency', 'agenda', 'agent', 'agents', 'ages', 'agf', 'aging', 'ago', 'agree', 'agreeable', 'agreed', 'agreement', 'agreements', 'agugc', 'ah', 'ahead', 'ahref', 'ai', 'aid', 'aids', 'aig', 'aim', 'ain', 'air', 'airmail', 'airport', 'aj', 'ak', 'akamai', 'al', 'alaska', 'alb', 'alberta', 'album', 'alert', 'algorithms', 'align', 'alink', 'alliance', 'alliances', 'allies', 'allow', 'allowed', 'allows', 'alsa', 'alt', 'alter', 'alternative', 'alternatives', 'amateur', 'amavis', 'amavisd', 'amazing', 'amazon', 'amber', 'ambitious', 'amember', 'amendment', 'america', 'american', 'americans', 'amfin', 'amounts', 'amp', 'amphetadesk', 'analysis', 'analyst', 'ancestral', 'ancient', 'andy', 'angeles', 'animal', 'animals', 'announced', 'announcing', 'annoying', 'annuaire', 'annual', 'annually', 'annuity', 'answer', 'answers', 'antenna', 'anti', 'antiabuse', 'antiquity', 'antivirus', 'anybody', 'anymore', 'anythinggoeshere', 'anytime', 'ao', 'aol', 'ap', 'apart', 'apartment', 'apartments', 'aphrodisia', 'api', 'apologies', 'apologize', 'app']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names()[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 5000)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We explore a number of different types of classifier models,  including two Naive Bayes approaches (Gaussian & Bernoulli), Decision Trees, Support Vector Machines, Adaptive Boosting and Random Forests.\n",
    "\n",
    "We split the dataset test and training sets in order to train and evaluate the performance of the different classifier models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below will be used to display summaries of each model. It also returns the model and accuracy measures for further use in a summary dataframe. \n",
    "\n",
    "For a spam detection use case:\n",
    "- the cost of false positives is high (i.e. misclassifying a legitimate email as spam would mean a use loses a valid communication which could be very important);\n",
    "- the cost of false negatives are low (i.e. the inconvenience of junk emails or risk of unwittingly clicking on malicious links);\n",
    "- and, therefore, there's little need to balance between two;\n",
    "\n",
    "Precision is measures the rate of false positives, recall the rate of false negatives, and F1 score the harmonic means balancing the two. For this assignment, we focus on precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [] # holds model and accuracy information\n",
    "\n",
    "def build_and_score_model(model, model_name, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    # Predict on test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Training set accuracy\n",
    "    train_acc = model.score(X_train,y_train)\n",
    "    print('Model training set accuracy: {} \\n'.format(train_acc))\n",
    "    \n",
    "    # Testing set accuracy\n",
    "    test_acc = model.score(X_test, y_test)\n",
    "    print('Model test set accuracy: {} \\n'.format(test_acc))\n",
    "    \n",
    "    # Precision\n",
    "    precision = classification_report(y_test, y_pred, output_dict=True)['1']['precision']\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    cm = pd.DataFrame(data = cm, columns = ['Predicted Ham', 'Predicted Spam'],\n",
    "            index = ['Actual Ham', 'Actual Spam'])\n",
    "    print(cm)\n",
    "    print('\\n')\n",
    "          \n",
    "    print(classification_report(y_test, y_pred, target_names=['ham','spam']))\n",
    "    \n",
    "    models.append([model_name, model, test_acc, precision])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes - Gaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this model, the likelihood of the features is assumed to follow a Gaussian distribution.  This model is typically better suited to continuous data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required because of complaint about the matrix being too sparse\n",
    "X_train = X_train.toarray()\n",
    "X_test = X_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate and train Gaussian Naive Bayes model\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The precision of the Gaussian Naive Bayes classifier is 0.93, and it misidentifies 5 spam emails as ham and 12 ham emails as spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training set accuracy: 0.9985714285714286 \n",
      "\n",
      "Model test set accuracy: 0.9433333333333334 \n",
      "\n",
      "             Predicted Ham  Predicted Spam\n",
      "Actual Ham             134              12\n",
      "Actual Spam              5             149\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.96      0.92      0.94       146\n",
      "        spam       0.93      0.97      0.95       154\n",
      "\n",
      "    accuracy                           0.94       300\n",
      "   macro avg       0.94      0.94      0.94       300\n",
      "weighted avg       0.94      0.94      0.94       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "build_and_score_model(gnb, 'NaiveBayesGaussian', X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes - Bernoulli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Bernoulli Naive Bayes model assumes that all features are binary -meaning that either s feature does, or does not, appear in the document. This kind of model typically performs better on shorter documents like emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate and train Gaussian Naive Bayes model\n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The precision of the Bernoulli Naive Bayes classifier is 0.99, and it misidentifies 21 spam emails as ham and 1 ham email as spam. While this model allows for more spam emails to be classified as ham (false positives) than Guassian Naive Bayers classifier, there were less actual ham emails classified as spam (false negatives)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training set accuracy: 0.93 \n",
      "\n",
      "Model test set accuracy: 0.9266666666666666 \n",
      "\n",
      "             Predicted Ham  Predicted Spam\n",
      "Actual Ham             145               1\n",
      "Actual Spam             21             133\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.87      0.99      0.93       146\n",
      "        spam       0.99      0.86      0.92       154\n",
      "\n",
      "    accuracy                           0.93       300\n",
      "   macro avg       0.93      0.93      0.93       300\n",
      "weighted avg       0.93      0.93      0.93       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "build_and_score_model(bnb, 'NaiveBayesBernoulli', X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of the two Naive Bayes models, the Bernoulli had a slightly lower accuracy but higher precision. For a real email classifier, this is a better result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=1e-07, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=88, splitter='best')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
    "    max_features=None, max_leaf_nodes=None,\n",
    "    min_impurity_decrease=1e-07, min_samples_leaf=1,\n",
    "    min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "    random_state=88, splitter='best')\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Decision Tree model doesn't improve upn the Naive Bayes classifiers in terms of accuracy (0.92) or precision (0.92). Classification errors both for ham and spam emails were 12 ham classified as spam and 13 spam classified as ham."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training set accuracy: 1.0 \n",
      "\n",
      "Model test set accuracy: 0.9166666666666666 \n",
      "\n",
      "             Predicted Ham  Predicted Spam\n",
      "Actual Ham             133              13\n",
      "Actual Spam             12             142\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.92      0.91      0.91       146\n",
      "        spam       0.92      0.92      0.92       154\n",
      "\n",
      "    accuracy                           0.92       300\n",
      "   macro avg       0.92      0.92      0.92       300\n",
      "weighted avg       0.92      0.92      0.92       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "build_and_score_model(dt, 'DecisionTree', X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machines is a classifier which makes use of a 'kernel trick' to efficiently transform data to a new space in which the margin between different classes can be maximized using a hyperplane.\n",
    "\n",
    "We employ two common kernels - **linear** and **radial basis function (RBF)** - to evaluate their respective performance.\n",
    "\n",
    "SVM kernels take different parameters depending on the kernel type.  The *C* parameter is a regularization term that penalizes misclassification (i.e. a lower value imposes a softer class boundary, or higher value a harder), and it is used for both linear and RBF kernels.  The RBF kernel also takes a *gamma* parameter, which controls the distance over which a given training example influences the boundary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function to perform a grid search to identify good candidates for *C* (for linear and RBF) and gamma (for RBF only) parameters.  Due to computational load, we limit the cross validation to five folds (optimally this would be 10)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure grid search for hyperparameter tuning at exponential increments\n",
    "def svm_tune_grid(X, y, kernel, nfolds):\n",
    "    \n",
    "    C = [.0001,.001,.01,.1,1,10]\n",
    "    gamma = [.0001,.001,.01,.1,1,10]\n",
    "    \n",
    "    # For linear kernels\n",
    "    if kernel == 'linear':\n",
    "        param_grid = {'C': C}\n",
    "        grid_search = GridSearchCV(svm.SVC(kernel=kernel), \n",
    "                                   param_grid, \n",
    "                                   cv=nfolds)\n",
    "    \n",
    "    # For RBF kernels\n",
    "    elif kernel == 'rbf':\n",
    "        param_grid = {'C': C, 'gamma': gamma}\n",
    "        grid_search = GridSearchCV(svm.SVC(kernel=kernel), \n",
    "                                   param_grid, \n",
    "                                   cv=nfolds)\n",
    "    \n",
    "    # Other kernels are not supported by this function\n",
    "    else:\n",
    "        print('Kernel not recognized or supported')\n",
    "        return\n",
    "    \n",
    "    grid_search.fit(X,y)\n",
    "    grid_search.best_params_\n",
    "    \n",
    "    return grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid search for optimal C and gamma in linear kernel\n",
    "svm_tune_grid(X_train, y_train, 'linear', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'gamma': 0.1}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid search for optimal C and gamma in radial basis function kernel\n",
    "svm_tune_grid(X_train, y_train, 'rbf', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the grid search returned an optimal *C* value of 1 for the linear kernel and 10 for the RBF kernel, and a *gamma* value of 1 for the RBF kernel, we fit the two versions of the SVM classifier accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we fit an SVM classifier with linear kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit SVM classifier with linear kernel on training set\n",
    "svm_lin = svm.SVC(C=1,  # identified by grid search\n",
    "               kernel='linear')\n",
    "svm_lin.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The precision of the linear kernel SVM classifier is 0.96, and it only misidentifies 7 spam emails as ham and 4 ham emails as spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training set accuracy: 0.9985714285714286 \n",
      "\n",
      "Model test set accuracy: 0.9633333333333334 \n",
      "\n",
      "             Predicted Ham  Predicted Spam\n",
      "Actual Ham             142               4\n",
      "Actual Spam              7             147\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.95      0.97      0.96       146\n",
      "        spam       0.97      0.95      0.96       154\n",
      "\n",
      "    accuracy                           0.96       300\n",
      "   macro avg       0.96      0.96      0.96       300\n",
      "weighted avg       0.96      0.96      0.96       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "build_and_score_model(svm_lin, 'SVMLinearKernel', X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we fit an SVM classifier with an RBF kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf', max_iter=-1,\n",
       "    probability=False, random_state=None, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit SVM classifier with RBF kernel on training set\n",
    "svm_rbf = svm.SVC(C=10,  # identified by grid search\n",
    "               kernel='rbf',\n",
    "                 gamma=1)  # identified by grid search\n",
    "svm_rbf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The precision of the RBF kernel SVM classifier is 0.95, and it only misidentifies 10 spam emails as ham and 4 ham emails as spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training set accuracy: 1.0 \n",
      "\n",
      "Model test set accuracy: 0.9533333333333334 \n",
      "\n",
      "             Predicted Ham  Predicted Spam\n",
      "Actual Ham             142               4\n",
      "Actual Spam             10             144\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.93      0.97      0.95       146\n",
      "        spam       0.97      0.94      0.95       154\n",
      "\n",
      "    accuracy                           0.95       300\n",
      "   macro avg       0.95      0.95      0.95       300\n",
      "weighted avg       0.95      0.95      0.95       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "build_and_score_model(svm_rbf, 'SVMRBFKernel', X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of the two SVM classifiers, the lineasr kernel performs incrementally better than the RBF kernel.  This means that a linear boundary in the hyperplane better distinguishes between the two classes.  As the RBF kernel requires greater computational resources, its poorer performance is a strong vote against it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaptive Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Adaptive Boosting classifier converts a set of weak classifiers into a strong one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
       "                   n_estimators=50, random_state=88)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada = AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
    "          learning_rate=1.0, n_estimators=50, random_state=88)\n",
    "ada.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Adaptive Boosting model nearly rivals the SVM models on precision (0.96) and accuracy (0.95) with only 9 errors: 2 ham emails classified as spam and 7 spam emails classified as ham."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training set accuracy: 1.0 \n",
      "\n",
      "Model test set accuracy: 0.95 \n",
      "\n",
      "             Predicted Ham  Predicted Spam\n",
      "Actual Ham             140               6\n",
      "Actual Spam              9             145\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.94      0.96      0.95       146\n",
      "        spam       0.96      0.94      0.95       154\n",
      "\n",
      "    accuracy                           0.95       300\n",
      "   macro avg       0.95      0.95      0.95       300\n",
      "weighted avg       0.95      0.95      0.95       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "build_and_score_model(ada, 'AdaptiveBoosting', X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forests are capable of growing multiple classification trees. To classify a new object from an input vector, put the input vector down each of the trees in the forest. Each tree gives a classification, and the tree votes for that class. The forest chooses the classification having the most votes of all the trees in the forest. They don't overfit, and you can run as many trees as you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=1e-07, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "                       oob_score=False, random_state=88, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=1e-07, min_samples_leaf=1,\n",
    "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "            n_estimators=10, n_jobs=1, oob_score=False, random_state=88,\n",
    "            verbose=0, warm_start=False)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Random Forest model achieves 0.97 precision which is the highest score so far. Only two ham emais are classified as spam. The accuracy of 0.98 is slightly lower than the SVM models due to the 10 spam emails incorrectly classified as ham. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training set accuracy: 0.9957142857142857 \n",
      "\n",
      "Model test set accuracy: 0.9766666666666667 \n",
      "\n",
      "             Predicted Ham  Predicted Spam\n",
      "Actual Ham             141               5\n",
      "Actual Spam              2             152\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      0.97      0.98       146\n",
      "        spam       0.97      0.99      0.98       154\n",
      "\n",
      "    accuracy                           0.98       300\n",
      "   macro avg       0.98      0.98      0.98       300\n",
      "weighted avg       0.98      0.98      0.98       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "build_and_score_model(rf, 'RandomForest', X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The `models` list that stored the models and performance metrics is unfolded to summarize the findings of this investigation in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_models(models):\n",
    "    table = pd.DataFrame(columns = ['model', 'acc_test', 'precision'])\n",
    "    \n",
    "    for m in models:\n",
    "        df = pd.DataFrame({'model': [m[0]], 'acc_test': [m[2]], 'precision': [m[3]]})\n",
    "        table = table.append(df, ignore_index=True)\n",
    "\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_82e5aa74_c722_11ea_9373_d0abd57ecbe1row0_col1 {\n",
       "            background-color:  #82bbdb;\n",
       "            color:  #000000;\n",
       "        }    #T_82e5aa74_c722_11ea_9373_d0abd57ecbe1row0_col2 {\n",
       "            background-color:  #dfebf7;\n",
       "            color:  #000000;\n",
       "        }    #T_82e5aa74_c722_11ea_9373_d0abd57ecbe1row1_col1 {\n",
       "            background-color:  #d6e6f4;\n",
       "            color:  #000000;\n",
       "        }    #T_82e5aa74_c722_11ea_9373_d0abd57ecbe1row1_col2 {\n",
       "            background-color:  #08306b;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_82e5aa74_c722_11ea_9373_d0abd57ecbe1row2_col1 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_82e5aa74_c722_11ea_9373_d0abd57ecbe1row2_col2 {\n",
       "            background-color:  #f7fbff;\n",
       "            color:  #000000;\n",
       "        }    #T_82e5aa74_c722_11ea_9373_d0abd57ecbe1row3_col1 {\n",
       "            background-color:  #1b69af;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_82e5aa74_c722_11ea_9373_d0abd57ecbe1row3_col2 {\n",
       "            background-color:  #2070b4;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_82e5aa74_c722_11ea_9373_d0abd57ecbe1row4_col1 {\n",
       "            background-color:  #4695c8;\n",
       "            color:  #000000;\n",
       "        }    #T_82e5aa74_c722_11ea_9373_d0abd57ecbe1row4_col2 {\n",
       "            background-color:  #2272b6;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_82e5aa74_c722_11ea_9373_d0abd57ecbe1row5_col1 {\n",
       "            background-color:  #58a1cf;\n",
       "            color:  #000000;\n",
       "        }    #T_82e5aa74_c722_11ea_9373_d0abd57ecbe1row5_col2 {\n",
       "            background-color:  #529dcc;\n",
       "            color:  #000000;\n",
       "        }    #T_82e5aa74_c722_11ea_9373_d0abd57ecbe1row6_col1 {\n",
       "            background-color:  #08306b;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_82e5aa74_c722_11ea_9373_d0abd57ecbe1row6_col2 {\n",
       "            background-color:  #3383be;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_82e5aa74_c722_11ea_9373_d0abd57ecbe1\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >model</th>        <th class=\"col_heading level0 col1\" >acc_test</th>        <th class=\"col_heading level0 col2\" >precision</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_82e5aa74_c722_11ea_9373_d0abd57ecbe1level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_82e5aa74_c722_11ea_9373_d0abd57ecbe1row0_col0\" class=\"data row0 col0\" >NaiveBayesGaussian</td>\n",
       "                        <td id=\"T_82e5aa74_c722_11ea_9373_d0abd57ecbe1row0_col1\" class=\"data row0 col1\" >0.943333</td>\n",
       "                        <td id=\"T_82e5aa74_c722_11ea_9373_d0abd57ecbe1row0_col2\" class=\"data row0 col2\" >0.925466</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_82e5aa74_c722_11ea_9373_d0abd57ecbe1level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_82e5aa74_c722_11ea_9373_d0abd57ecbe1row1_col0\" class=\"data row1 col0\" >NaiveBayesBernoulli</td>\n",
       "                        <td id=\"T_82e5aa74_c722_11ea_9373_d0abd57ecbe1row1_col1\" class=\"data row1 col1\" >0.926667</td>\n",
       "                        <td id=\"T_82e5aa74_c722_11ea_9373_d0abd57ecbe1row1_col2\" class=\"data row1 col2\" >0.992537</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_82e5aa74_c722_11ea_9373_d0abd57ecbe1level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_82e5aa74_c722_11ea_9373_d0abd57ecbe1row2_col0\" class=\"data row2 col0\" >DecisionTree</td>\n",
       "                        <td id=\"T_82e5aa74_c722_11ea_9373_d0abd57ecbe1row2_col1\" class=\"data row2 col1\" >0.916667</td>\n",
       "                        <td id=\"T_82e5aa74_c722_11ea_9373_d0abd57ecbe1row2_col2\" class=\"data row2 col2\" >0.916129</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_82e5aa74_c722_11ea_9373_d0abd57ecbe1level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_82e5aa74_c722_11ea_9373_d0abd57ecbe1row3_col0\" class=\"data row3 col0\" >SVMLinearKernel</td>\n",
       "                        <td id=\"T_82e5aa74_c722_11ea_9373_d0abd57ecbe1row3_col1\" class=\"data row3 col1\" >0.963333</td>\n",
       "                        <td id=\"T_82e5aa74_c722_11ea_9373_d0abd57ecbe1row3_col2\" class=\"data row3 col2\" >0.973510</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_82e5aa74_c722_11ea_9373_d0abd57ecbe1level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_82e5aa74_c722_11ea_9373_d0abd57ecbe1row4_col0\" class=\"data row4 col0\" >SVMRBFKernel</td>\n",
       "                        <td id=\"T_82e5aa74_c722_11ea_9373_d0abd57ecbe1row4_col1\" class=\"data row4 col1\" >0.953333</td>\n",
       "                        <td id=\"T_82e5aa74_c722_11ea_9373_d0abd57ecbe1row4_col2\" class=\"data row4 col2\" >0.972973</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_82e5aa74_c722_11ea_9373_d0abd57ecbe1level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_82e5aa74_c722_11ea_9373_d0abd57ecbe1row5_col0\" class=\"data row5 col0\" >AdaptiveBoosting</td>\n",
       "                        <td id=\"T_82e5aa74_c722_11ea_9373_d0abd57ecbe1row5_col1\" class=\"data row5 col1\" >0.950000</td>\n",
       "                        <td id=\"T_82e5aa74_c722_11ea_9373_d0abd57ecbe1row5_col2\" class=\"data row5 col2\" >0.960265</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_82e5aa74_c722_11ea_9373_d0abd57ecbe1level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_82e5aa74_c722_11ea_9373_d0abd57ecbe1row6_col0\" class=\"data row6 col0\" >RandomForest</td>\n",
       "                        <td id=\"T_82e5aa74_c722_11ea_9373_d0abd57ecbe1row6_col1\" class=\"data row6 col1\" >0.976667</td>\n",
       "                        <td id=\"T_82e5aa74_c722_11ea_9373_d0abd57ecbe1row6_col2\" class=\"data row6 col2\" >0.968153</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x22e6a514848>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = summarize_models(models)\n",
    "table.style.background_gradient(cmap='Blues')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here two principal metrics are used to determine how 'good' a model is. The Random Forest model is the most accurate, with the linear SVM close behind. However, as stated earlier, a spam email classifier is more concerned with penalizing misclassifications of ham emails as spam while being more tolerant of the occasional spam email going through to the ham box. The precision metric reveals the Naive Bayes Bernoulli model to be the most precise, with only two ham emails classified as spam.\n",
    "\n",
    "Each of these models are select below by index. \n",
    "\n",
    "Based on the consistenly high scores in both test set accuracy and precision, the SVMLinearKernel delivers the best overall performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=1e-07, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "                       oob_score=False, random_state=88, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_accurate_model = models[6][1] # Select the best model by index from the table above\n",
    "most_accurate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_precise_model = models[1][1] # Select the best model by index from the table above\n",
    "most_precise_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To quickly examine why the Random Forest model was so accurate in identifying spam emails correctly, we take a look at the most importance features. The majority of these features are HTML tags. This tells us that spam emails are easily identifiable by the amount of HTML present in the body of an email which differentiates them from emails whose bodies are simply plain text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Importance provides a score that indicates how useful or valuable each feature was in the construction of the boosted decision trees within the model. The more an attribute is used to make key decisions within decision trees, the higher its relative importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_importance = [i for i in zip(vectorizer.get_feature_names(), most_accurate_model.feature_importances_)]\n",
    "feature_importance_20 = sorted(feature_importance, key = lambda x: x[1], reverse=True)[:20]\n",
    "features = [f for (f, i) in feature_importance_20]\n",
    "importance = [i for (f, i) in feature_importance_20]\n",
    "plt.figure(figsize=(18, 8))\n",
    "plt.yscale('log', nonposy='clip')\n",
    "plt.bar(range(len(importance)), importance, align='center')\n",
    "plt.xticks(range(len(importance)), features, rotation='vertical', color = 'blue')\n",
    "plt.title('Top 20 Importance Features for Most Precise Model')\n",
    "plt.ylabel('Importance')\n",
    "plt.xlabel('Feature Variables')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- http://www.cs.ucf.edu/courses/cap5636/fall2011/nltk.pdf\n",
    "- https://bbengfort.github.io/tutorials/2016/05/19/text-classification-nltk-sckit-learn.html\n",
    "- https://www.cs.bgu.ac.il/~elhadad/nlp16/spam_classifier.html\n",
    "- https://towardsdatascience.com/tf-idf-for-document-ranking-from-scratch-in-python-on-real-world-dataset-796d339a4089\n",
    "- https://datawhatnow.com/feature-importance/\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo('6n50CxNnC1E')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
