{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Name Gender Classifier\n",
    "\n",
    "*Natural Language Processing, Classification*\n",
    "\n",
    "Jeremy OBrien, Mael Illien, Vanita Thompson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This project aims to build a classifier capable of distinguishing the gender of a name, combining techniques from Machine Learning and Natural Language Processing.\n",
    "\n",
    "For this project, we work with the 'names' corpus contained within NLTK.\n",
    "\n",
    "We start our work by restructuring some of the guidelines from Chapter 6 of 'Natural Language Processing with Python'. The function 'test_classifier' performs most of the work: splitting the data into train and test sets, extracting features, training the model, and predicting based on the test set. \n",
    "\n",
    "In the feature engineering section, we build on examples from the text and develop new features to evaluate. \n",
    "\n",
    "We study three classifiers - NaiveBayes, DecisionTree, and MaxEntropy - in their respective sections, and compare results in a summary table in the conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import nltk, re, pprint\n",
    "from nltk.corpus import names\n",
    "from nltk.classify import apply_features\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For ease of comparison, we compile a list of the models created for this project and their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [] # Will contain tuples (classifier, class_name, gf_name, acc_devtest, acc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import & Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NLTK 'names' corpus contains both male and female names in separate text files. The code below extracts the names from both files, assigns a gender to the name, and stores the information in a list of tuples. The labeled names are shuffled to randomize their distribution over the train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('marietta', 'male'),\n",
       " ('price', 'male'),\n",
       " ('almeda', 'female'),\n",
       " ('hendrika', 'female'),\n",
       " ('reggie', 'male'),\n",
       " ('mindy', 'female'),\n",
       " ('cosette', 'female'),\n",
       " ('logan', 'male'),\n",
       " ('martha', 'female'),\n",
       " ('ulrika', 'female')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build dataset removing any white space and names with hyphens\n",
    "labeled_names = ([(name.lower().strip(), 'male') for name in names.words('male.txt') if name.isalpha()] + \n",
    "         [(name.lower().strip(), 'female') for name in names.words('female.txt') if name.isalpha()])\n",
    "\n",
    "random.seed(620)\n",
    "random.shuffle(labeled_names)\n",
    "labeled_names[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7904"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labeled_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Classifier\n",
    "\n",
    "The **test_classifier** function takes as arguments a corpus of labeled names, a function to extract features from that corpus, and a classifier type. It splits the datasets into three parts: a training set, a devtest set, and a test set. It trains the classifier and returns the model and its accuracy on both test sets. This information is made available to compare between approaches to feature engineering and model types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_classifier(names_corpus, gender_features_function, classifier_type):\n",
    "\n",
    "    # Train test split (corrected)\n",
    "    train_names = names_corpus[1000:]\n",
    "    devtest_names = names_corpus[0:500]\n",
    "    test_names = names_corpus[500:1000]\n",
    "    \n",
    "    # Apply features\n",
    "    train_set = [(gender_features_function(n), gender) for (n, gender) in train_names]\n",
    "    devtest_set = [(gender_features_function(n), gender) for (n, gender) in devtest_names]\n",
    "    test_set = [(gender_features_function(n), gender) for (n, gender) in test_names]\n",
    "    \n",
    "    # Classify and print score; if Maximum Entropy, use trace to limit diagnostic output on screen\n",
    "    if classifier_type == nltk.ConditionalExponentialClassifier:\n",
    "        classifier = classifier_type.train(train_set, trace=0)\n",
    "    else:\n",
    "        classifier = classifier_type.train(train_set)\n",
    "    acc_devtest = round(nltk.classify.accuracy(classifier, devtest_set), 3)\n",
    "    acc_test = round(nltk.classify.accuracy(classifier, test_set), 3)\n",
    "    print('Dev test set accuracy: ' + str(acc_devtest))\n",
    "    print('Test set accuracy: ' + str(acc_test))\n",
    "    \n",
    "    #classifier.show_most_informative_features(5)\n",
    "    \n",
    "    class_name = classifier_type.__name__\n",
    "    gf_name = gender_features_function.__name__\n",
    "    models.append((classifier, class_name, gf_name, acc_devtest, acc_test))\n",
    "    \n",
    "    return classifier  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We explore a number of approaches to breaking down first names and extracting features to train the classifier model. These different approaches may lend the classifiers more or less power to efficiently discriminate between female and male names.\n",
    "\n",
    "We include features defined in the text and augment them with additional appraoches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Approach \\#1**:  The last letter of the name. While a simple approach, the particular letter at the end of a name can be powerful predictor of gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features1(name):\n",
    "    return {'last_letter': name[-1]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Approach \\#2**:  The first letter, last letter, and presence and counts of all letters in the name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features2(name):\n",
    "    features = {}\n",
    "    features[\"firstletter\"] = name[0]\n",
    "    features[\"lastletter\"] = name[-1]\n",
    "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
    "        features[\"count(%s)\" % letter] = name.count(letter)\n",
    "        features[\"has(%s)\" % letter] = (letter in name)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Approach \\#3**:  The last and penultimate letters in the name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features3(name):\n",
    "    return {'suffix1': name[-1:], 'suffix2': name[-2:]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Approach \\#4**:  The first letter, last letter, presence and counts of all letters, and suffixes (final sequence of one, two, or three letters) of the name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features4(name):\n",
    "    features = {}\n",
    "    features[\"firstletter\"] = name[0]\n",
    "    features[\"lastletter\"] = name[-1]\n",
    "    features['suffix1'] =  name[-1:]\n",
    "    features['suffix2'] = name[-2:]\n",
    "    features['suffix3'] = name[-3:]\n",
    "    for letter in 'abcdefghijklmnopqrstuvwxyz':\n",
    "        features[\"count(%s)\" % letter] = name.count(letter)\n",
    "        features[\"has(%s)\" % letter] = (letter in name)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Approach \\#5**:  Whether the first letter or last letter of the name are vowels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features5(name):\n",
    "    features = {}\n",
    "    features[\"vowel_start\"] = int(name[0] in 'aeiuoy')\n",
    "    features[\"vowel_end\"] = int(name[-1] in 'aeiuoy')\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Approach \\#6**:  The length of the name, with an arbitrary cutoff of five letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features6(name):\n",
    "    features = {}\n",
    "    features[\"short_name\"] = int(len(name) < 4)\n",
    "    features['length'] = len(name)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifiers\n",
    "\n",
    "In this section, we define the model parameters and call the **test_classifier** function. Accuracy scores on both test sets are outputted for each model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes\n",
    "\n",
    "With a Naive Bayes classifier, every feature is used to determine which label (male or female) should be assigned to a given input name. The prior probability (the proportion of male and females names in the training data) is modulated by the contribution from each feature to arrive at a likelihood estimate for each label. The label with the highest probability is then assigned. Note that this classifier works under the assumption that each feature is independent of every other features which can be unrealistic, hence the qualifier 'naive'. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Naive Bayes, Approach \\#1**: We test our first feature (last letter only) and by displaying the most informative features, we discover the important classifying power of the last letter 'a' which is nearly 35 times more likely to be a female name. The accuracy score is solid for a single feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev test set accuracy: 0.75\n",
      "Test set accuracy: 0.732\n",
      "Most Informative Features\n",
      "             last_letter = 'a'            female : male   =     34.9 : 1.0\n",
      "             last_letter = 'k'              male : female =     29.2 : 1.0\n",
      "             last_letter = 'f'              male : female =     24.9 : 1.0\n",
      "             last_letter = 'p'              male : female =     11.0 : 1.0\n",
      "             last_letter = 'd'              male : female =     10.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "nb_mod1 = test_classifier(labeled_names, gender_features1, nltk.NaiveBayesClassifier)\n",
    "nb_mod1.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Naive Bayes, Approach \\#2**: When including the first letter, last letter, and the presence and count of all alphabet letters, we see that the first five most informative features are identical to the first approach. We print the next five features to see the contribution of the added features. Only one new feature (having two 'v's) makes it into the top 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev test set accuracy: 0.776\n",
      "Test set accuracy: 0.76\n",
      "Most Informative Features\n",
      "              lastletter = 'a'            female : male   =     34.9 : 1.0\n",
      "              lastletter = 'k'              male : female =     29.2 : 1.0\n",
      "              lastletter = 'f'              male : female =     24.9 : 1.0\n",
      "              lastletter = 'p'              male : female =     11.0 : 1.0\n",
      "              lastletter = 'd'              male : female =     10.3 : 1.0\n",
      "              lastletter = 'v'              male : female =      9.6 : 1.0\n",
      "              lastletter = 'm'              male : female =      9.5 : 1.0\n",
      "                count(v) = 2              female : male   =      9.4 : 1.0\n",
      "              lastletter = 'o'              male : female =      8.9 : 1.0\n",
      "              lastletter = 'r'              male : female =      7.9 : 1.0\n"
     ]
    }
   ],
   "source": [
    "nb_mod2 = test_classifier(labeled_names, gender_features2, nltk.NaiveBayesClassifier)\n",
    "nb_mod2.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Naive Bayes, Approach \\#3**: Suffixes of size two have a strong contribution. The top three suffixes also have 'a' as their last letter and are very indicative of female names. A suffix a size one is equivalent to the last letter of a name so it is no surprise to see suffix1 = 'a' appearing again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev test set accuracy: 0.764\n",
      "Test set accuracy: 0.74\n",
      "Most Informative Features\n",
      "                 suffix2 = 'na'           female : male   =     97.5 : 1.0\n",
      "                 suffix2 = 'la'           female : male   =     73.8 : 1.0\n",
      "                 suffix2 = 'ia'           female : male   =     52.4 : 1.0\n",
      "                 suffix2 = 'us'             male : female =     39.5 : 1.0\n",
      "                 suffix2 = 'ld'             male : female =     38.6 : 1.0\n",
      "                 suffix1 = 'a'            female : male   =     34.9 : 1.0\n",
      "                 suffix2 = 'sa'           female : male   =     30.9 : 1.0\n",
      "                 suffix2 = 'ta'           female : male   =     29.9 : 1.0\n",
      "                 suffix2 = 'rd'             male : female =     29.6 : 1.0\n",
      "                 suffix1 = 'k'              male : female =     29.2 : 1.0\n"
     ]
    }
   ],
   "source": [
    "nb_mod3 = test_classifier(labeled_names, gender_features3, nltk.NaiveBayesClassifier)\n",
    "nb_mod3.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Naive Bayes, Approach \\#4**: When three-letter suffixes are included and combined with the previous features, we encounter the highest accuracy on the test set for a Naive Bayers model so far: 0.782. However, the top 10 features have large overlap with the previous results so the added accuracy is provided by the added features lower in the informative power list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev test set accuracy: 0.792\n",
      "Test set accuracy: 0.782\n",
      "Most Informative Features\n",
      "                 suffix2 = 'na'           female : male   =     97.5 : 1.0\n",
      "                 suffix2 = 'la'           female : male   =     73.8 : 1.0\n",
      "                 suffix2 = 'ia'           female : male   =     52.4 : 1.0\n",
      "                 suffix2 = 'us'             male : female =     39.5 : 1.0\n",
      "                 suffix2 = 'ld'             male : female =     38.6 : 1.0\n",
      "              lastletter = 'a'            female : male   =     34.9 : 1.0\n",
      "                 suffix1 = 'a'            female : male   =     34.9 : 1.0\n",
      "                 suffix2 = 'sa'           female : male   =     30.9 : 1.0\n",
      "                 suffix2 = 'ta'           female : male   =     29.9 : 1.0\n",
      "                 suffix2 = 'rd'             male : female =     29.6 : 1.0\n"
     ]
    }
   ],
   "source": [
    "nb_mod4 = test_classifier(labeled_names, gender_features4, nltk.NaiveBayesClassifier)\n",
    "nb_mod4.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Naive Bayes, Approach \\#5**: By evaluating letters on whether they are vowels, we find that names ending in vowels are 2.3 times more likely to be female names while the converse (ending in a consonant), is true for males to a greater extent. Whether the starting letter was a vowel or consonant provided little information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev test set accuracy: 0.728\n",
      "Test set accuracy: 0.714\n",
      "Most Informative Features\n",
      "               vowel_end = 0                male : female =      3.4 : 1.0\n",
      "               vowel_end = 1              female : male   =      2.3 : 1.0\n",
      "             vowel_start = 1              female : male   =      1.1 : 1.0\n",
      "             vowel_start = 0                male : female =      1.0 : 1.0\n"
     ]
    }
   ],
   "source": [
    "nb_mod5 = test_classifier(labeled_names, gender_features5, nltk.NaiveBayesClassifier)\n",
    "nb_mod5.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Naive Bayes, Approach \\#6**: With an accuracy score of 0.644, the number of letters in a name is the worst feature to classify gender thus far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev test set accuracy: 0.67\n",
      "Test set accuracy: 0.644\n",
      "Most Informative Features\n",
      "                  length = 2                male : female =      2.3 : 1.0\n",
      "                  length = 12               male : female =      2.3 : 1.0\n",
      "              short_name = 1                male : female =      2.0 : 1.0\n",
      "                  length = 3                male : female =      2.0 : 1.0\n",
      "                  length = 10             female : male   =      1.9 : 1.0\n",
      "                  length = 9              female : male   =      1.4 : 1.0\n",
      "                  length = 4                male : female =      1.2 : 1.0\n",
      "                  length = 7              female : male   =      1.1 : 1.0\n",
      "                  length = 8              female : male   =      1.1 : 1.0\n",
      "                  length = 5              female : male   =      1.1 : 1.0\n"
     ]
    }
   ],
   "source": [
    "nb_mod6 = test_classifier(labeled_names, gender_features6, nltk.NaiveBayesClassifier)\n",
    "nb_mod6.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision trees are made up of two components: decision nodes, which check feature values, and leaf nodes, which assign labels. The algorithm computes a decision stump for each possible feature, and evaluates which feature achieves the best accuracy on the training data. It then iteratively checks every leaf of the stump and computes a new decision stump based on the feature that maximizes the accuracy as before.\n",
    "\n",
    "We leverage pseudocode and truncate to a pretty_format output to help understand the structure of each decision tree below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Tree, Approach \\#1**: The first approach uses only a single feature (the last letter) which doesn't result in much of a tree. However, the accuracy score is quite similar to the Naives Bayes model using the same feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev test set accuracy: 0.75\n",
      "Test set accuracy: 0.732\n"
     ]
    }
   ],
   "source": [
    "dt_mod1 = test_classifier(labeled_names, gender_features1, nltk.DecisionTreeClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Tree, Approach \\#2**: When a wider set of features are use a branching structure becomes apparent, with indents representing leaf nodes. We gain decent accuracy points from the added complexity and get the best model so far with an accuracy of 0.798."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev test set accuracy: 0.788\n",
      "Test set accuracy: 0.798\n",
      "lastletter=a? ..................... female\n",
      "lastletter=b? ..................... female\n",
      "  firstletter=a? .................. male\n",
      "  firstletter=b? .................. female\n",
      "    has(a)=False? ................. male\n",
      "    has(a)=True? .................. female\n",
      "  firstletter=c? .................. female\n",
      "    count(y)=0? ................... male\n",
      "    count(y)=1? ................... female\n",
      "  firstletter=d? .................. female\n",
      "  firstletter=g? .................. male\n",
      "  firstletter=j? .................. male\n",
      "  firstletter=k? .................. male\n",
      "  firstletter=l? .................. female\n",
      "  firstletter=m? .................. female\n",
      "  firstletter=r? .................. male\n",
      "  firstletter=t? .................. male\n",
      "  firstletter=w? .................. male\n",
      "  firstletter=z? .................. male\n",
      "lastletter=c? ..................... male\n",
      "lastletter=d? ..................... female\n",
      "  count(i)=2? ..................... male\n",
      "    firstletter=b? ................ female\n",
      "    firstletter=h? ................ ma\n"
     ]
    }
   ],
   "source": [
    "dt_mod2 = test_classifier(labeled_names, gender_features2, nltk.DecisionTreeClassifier)\n",
    "print(dt_mod2.pretty_format(width=50, prefix='', depth=4)[:1005]) # alternate to pseudocode function call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Tree, Approach \\#3**: In this approach, only suffixes of size 2 form the leaves of the tree. The score is somewhere in between the first two approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev test set accuracy: 0.76\n",
      "Test set accuracy: 0.78\n",
      "suffix2=aa? ....................... male\n",
      "suffix2=ab? ....................... male\n",
      "suffix2=ac? ....................... male\n",
      "suffix2=ad? ....................... male\n",
      "suffix2=ae? ....................... female\n",
      "suffix2=af? ....................... male\n",
      "suffix2=ag? ....................... female\n",
      "suffix2=ah? ....................... female\n",
      "suffix2=ai? ....................... male\n",
      "suffix2=aj? ....................... male\n",
      "suffix2=ak? ....................... male\n",
      "suffix2=al? ....................... femal\n"
     ]
    }
   ],
   "source": [
    "dt_mod3 = test_classifier(labeled_names, gender_features3, nltk.DecisionTreeClassifier)\n",
    "print(dt_mod3.pretty_format(width=50, prefix='', depth=4)[:499])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Tree, Approach \\#4**: While adding more features increases complexity, it has actually reduced the accuracy compared with the preceding approaches. This is likely due to the fact that as the tree descends down into leaves there is less and less training data available to generalize, leading to overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev test set accuracy: 0.754\n",
      "Test set accuracy: 0.742\n",
      "suffix3=aac? ...................... male\n",
      "suffix3=aak? ...................... male\n",
      "suffix3=aba? ...................... female\n",
      "suffix3=abe? ...................... male\n",
      "suffix3=abi? ...................... male\n",
      "suffix3=abs? ...................... female\n",
      "suffix3=aby? ...................... male\n",
      "  firstletter=b? .................. male\n",
      "  firstletter=g? .................. female\n",
      "suffix3=ace? ...................... female\n",
      "  firstletter=a? .................. female\n",
      "  firstletter=c? .................. female\n",
      "  firstletter=e? .................. male\n",
      "  firstletter=g? .................. female\n",
      "  firstletter=h? .................. male\n",
      "  firstletter=i? .................. male\n",
      "  firstletter=k? .................. female\n",
      "  firstletter=m? .................. male\n",
      "  firstletter=s? .................. male\n",
      "  firstletter=w? .................. male\n",
      "suffix3=ach? ...................... male\n",
      "suffix3=aci? ...................... female\n",
      "suffix3=ack? ...................... male\n",
      "suffix3=aco? ...................... mal\n"
     ]
    }
   ],
   "source": [
    "dt_mod4 = test_classifier(labeled_names, gender_features4, nltk.DecisionTreeClassifier)\n",
    "print(dt_mod4.pretty_format(width=50, prefix='', depth=4)[:1001])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Tree, Approach \\#5 and \\#6**: The next two approaches yield one-level trees without additional branching. Their accuracy scores are similar to the Naive Bayes approaches using the same feature sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev test set accuracy: 0.728\n",
      "Test set accuracy: 0.714\n",
      "if vowel_end == 0: return 'male'\n",
      "if vowel_end == 1: return 'female'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_mod5 = test_classifier(labeled_names, gender_features5, nltk.DecisionTreeClassifier)\n",
    "print(dt_mod5.pseudocode(depth=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev test set accuracy: 0.67\n",
      "Test set accuracy: 0.644\n",
      "if length == 10: return 'female'\n",
      "if length == 11: return 'female'\n",
      "if length == 12: return 'male'\n",
      "if length == 13: return 'female'\n",
      "if length == 2: return 'male'\n",
      "if length == 3: return 'male'\n",
      "if length == 4: return 'female'\n",
      "if length == 5: return 'female'\n",
      "if length == 6: return 'female'\n",
      "if length == 7: return 'female'\n",
      "if length == 8: return 'female'\n",
      "if length == 9: return 'female'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_mod6 = test_classifier(labeled_names, gender_features6, nltk.DecisionTreeClassifier)\n",
    "print(dt_mod6.pseudocode(depth=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using probabilites to set model parameters as the Naive Bayes classifier does, the Maximum Entropy Model (or [MaxEntropy](https://web.stanford.edu/class/cs124/lec/Maximum_Entropy_Classifiers.pdf)) searches for the set of parameters that maximize model performance. The property of [entropy](https://lost-contact.mit.edu/afs/cs.pitt.edu/projects/nltk/docs/tutorial/classifying/nochunks.html#maxent) entails uniformity of the distribution where there isn't empirical evidence that would constrain that uniformity.  \n",
    "\n",
    "Unlike Naive Bayes, MaxEntropy does not assume independence of features, and so is not negatively impacted when there is dependence between features - which can often be the case. As MaxEntropy captures the structure of the training data, the more features it uses the stronger the constraint of empirical consistency becomes.\n",
    "\n",
    "MaxEntropy is a conditional classifier, meaning it can be used to determine the most likely label for a given input or conversely how likely a label is for that input.  In addition to the foregoing, a generative classifier like Naive Bayes can also estimate the most likely input value, how likely an input value is, as well as the same given an input label.\n",
    "\n",
    "NLTK offers two MaxEntropy algorithms out of the box: Generalized Iterative Scaling (GIS) and Improved Iterative Scaling (IIS). Iterative optimization using these algorithms can be time consuming, and the Wikipedia article on [MaxEntropy](https://en.wikipedia.org/wiki/Maximum_entropy_probability_distribution) and the literature (['A comparison of algorithms for maximum entropy parameter estimation'](http://luthuli.cs.uiuc.edu/~daf/courses/Opt-2017/Papers/p18-malouf.pdf)) note that gradient-based methods, such as coordinate descent and limited memory L-BFGS and LMBVM are preferable for their improved computational performance. While NLTK previously offered additional classifier algorithms through SciPy, it seems support has lapsed in the latest SciPy releases.  Given the outdated SciPy support, for this project we implement MaxEntropy using the GIS algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Maximum Entropy, Approach \\#1**: Using only the last letter of the name leads to swift convergence. Interestingly, the letters 'c' and 'a' in the last position are the most informative features and classify as male. This contrasts with the Naive Bayes model, where 'a' is highlighly ranked by 'c' is not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev test set accuracy: 0.75\n",
      "Test set accuracy: 0.732\n",
      "   6.644 last_letter=='c' and label is 'male'\n",
      "  -4.908 last_letter=='a' and label is 'male'\n",
      "  -3.524 last_letter=='f' and label is 'female'\n",
      "  -3.415 last_letter=='k' and label is 'female'\n",
      "  -2.170 last_letter=='p' and label is 'female'\n",
      "  -2.000 last_letter=='v' and label is 'female'\n",
      "  -1.862 last_letter=='d' and label is 'female'\n",
      "  -1.788 last_letter=='m' and label is 'female'\n",
      "  -1.785 last_letter=='i' and label is 'male'\n",
      "  -1.692 last_letter=='o' and label is 'female'\n"
     ]
    }
   ],
   "source": [
    "me_mod1 = test_classifier(labeled_names, gender_features1, nltk.ConditionalExponentialClassifier)\n",
    "me_mod1.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Maximum Entropy, Approach \\#2**: Including the first letter and counts of all letters improves accuracy, but with a noticeable impact on computational performance. Some first letters and shorter counts are top ten features, demonstrating the contribution to performance these features have. Even after most of the 100 iterations the model continues to improve incrementally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev test set accuracy: 0.812\n",
      "Test set accuracy: 0.788\n",
      "  -4.143 lastletter=='a' and label is 'male'\n",
      "  -3.001 lastletter=='k' and label is 'female'\n",
      "  -2.925 lastletter=='f' and label is 'female'\n",
      "  -2.835 count(v)==2 and label is 'male'\n",
      "   2.354 count(j)==2 and label is 'female'\n",
      "  -1.959 lastletter=='p' and label is 'female'\n",
      "  -1.786 lastletter=='v' and label is 'female'\n",
      "  -1.613 lastletter=='m' and label is 'female'\n",
      "  -1.612 lastletter=='d' and label is 'female'\n",
      "  -1.426 lastletter=='o' and label is 'female'\n"
     ]
    }
   ],
   "source": [
    "me_mod2 = test_classifier(labeled_names, gender_features2, nltk.ConditionalExponentialClassifier)\n",
    "me_mod2.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Maximum Entropy, Approach \\#3**: Including the last two letters of the name does not improve upon the accuracy of just using the final letter.  As it takes noticeably longer to process and seven iterations to reach an optimum, this is not a strong candidate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev test set accuracy: 0.758\n",
      "Test set accuracy: 0.776\n",
      "  11.406 suffix2=='aa' and label is 'male'\n",
      "  11.406 suffix2=='ua' and label is 'male'\n",
      "   9.770 suffix2=='iv' and label is 'female'\n",
      "   8.989 suffix2=='oo' and label is 'female'\n",
      "   8.148 suffix2=='ym' and label is 'female'\n",
      "  -7.787 suffix1=='f' and label is 'female'\n",
      "   7.468 suffix2=='lu' and label is 'female'\n",
      "  -7.409 suffix1=='k' and label is 'female'\n",
      "   7.264 suffix2=='rj' and label is 'female'\n",
      "   6.941 suffix2=='rb' and label is 'female'\n"
     ]
    }
   ],
   "source": [
    "me_mod3 = test_classifier(labeled_names, gender_features3, nltk.ConditionalExponentialClassifier)\n",
    "me_mod3.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Maximum Entropy, Approach \\#4**: Adding two and three-letter suffixes to first letter, last letter, and counts delivers the best accuracy of all models (including Naive Bayers and Decision Trees) so far: 0.812. In exchange, the model takes a good amount of time to run, and continues to improve after 90 iterations. With the exception of the final letter 'a' classifying male, two- and three-letter suffixes have the most impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev test set accuracy: 0.808\n",
      "Test set accuracy: 0.812\n",
      "   4.220 suffix3=='zra' and label is 'male'\n",
      "   3.986 suffix3=='hna' and label is 'male'\n",
      "   3.539 suffix3=='ous' and label is 'female'\n",
      "   3.212 suffix3=='tya' and label is 'male'\n",
      "   3.139 suffix3=='ild' and label is 'female'\n",
      "   3.095 suffix3=='eza' and label is 'male'\n",
      "   3.032 suffix3=='bev' and label is 'female'\n",
      "  -3.001 suffix3=='bel' and label is 'male'\n",
      "  -2.916 suffix2=='na' and label is 'male'\n",
      "  -2.834 suffix2=='la' and label is 'male'\n"
     ]
    }
   ],
   "source": [
    "me_mod4 = test_classifier(labeled_names, gender_features4, nltk.ConditionalExponentialClassifier)\n",
    "me_mod4.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Maximum Entropy, Approach \\#5 and \\#6**: The final two approaches - whether first / last letters are vowels, and the length of names - yield the worst accuracy measures of the MaxEntropy models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev test set accuracy: 0.728\n",
      "Test set accuracy: 0.714\n",
      "  -1.101 vowel_end==1 and label is 'male'\n",
      "  -0.837 vowel_end==0 and label is 'female'\n",
      "   0.536 vowel_end==0 and label is 'male'\n",
      "   0.474 vowel_end==1 and label is 'female'\n",
      "  -0.258 vowel_start==1 and label is 'male'\n",
      "   0.190 vowel_start==1 and label is 'female'\n",
      "  -0.185 vowel_start==0 and label is 'male'\n",
      "   0.147 vowel_start==0 and label is 'female'\n"
     ]
    }
   ],
   "source": [
    "me_mod5 = test_classifier(labeled_names, gender_features5, nltk.ConditionalExponentialClassifier)\n",
    "me_mod5.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev test set accuracy: 0.67\n",
      "Test set accuracy: 0.644\n",
      "   5.256 length==13 and label is 'female'\n",
      "  -0.846 length==10 and label is 'male'\n",
      "  -0.544 length==12 and label is 'female'\n",
      "  -0.487 length==9 and label is 'male'\n",
      "   0.430 length==12 and label is 'male'\n",
      "   0.414 length==10 and label is 'female'\n",
      "   0.298 length==9 and label is 'female'\n",
      "  -0.295 length==11 and label is 'male'\n",
      "  -0.284 length==7 and label is 'male'\n",
      "  -0.278 length==8 and label is 'male'\n"
     ]
    }
   ],
   "source": [
    "me_mod6 = test_classifier(labeled_names, gender_features6, nltk.ConditionalExponentialClassifier)\n",
    "me_mod6.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We conclude by summarizing all the models we have tested. This summary is shown both in the order of testing, and ranked by accuracy on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_models(models):\n",
    "    table = pd.DataFrame(columns = ['class', 'features', 'accuracy_devtest', 'accuracy_test'])\n",
    "    \n",
    "    for m in models:\n",
    "        df = pd.DataFrame({'class': [m[1]], 'features': [m[2]], 'accuracy_devtest': [m[3]], 'accuracy_test': [m[4]]})\n",
    "        table = table.append(df, ignore_index=True)\n",
    "\n",
    "    return table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>features</th>\n",
       "      <th>accuracy_devtest</th>\n",
       "      <th>accuracy_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MaxentClassifier</td>\n",
       "      <td>gender_features4</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>gender_features2</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MaxentClassifier</td>\n",
       "      <td>gender_features2</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>gender_features4</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>gender_features3</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MaxentClassifier</td>\n",
       "      <td>gender_features3</td>\n",
       "      <td>0.758</td>\n",
       "      <td>0.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>gender_features2</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>gender_features4</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>gender_features3</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MaxentClassifier</td>\n",
       "      <td>gender_features1</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>gender_features1</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>gender_features1</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>gender_features5</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>gender_features5</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>MaxentClassifier</td>\n",
       "      <td>gender_features5</td>\n",
       "      <td>0.728</td>\n",
       "      <td>0.714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>gender_features6</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>gender_features6</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MaxentClassifier</td>\n",
       "      <td>gender_features6</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     class          features  accuracy_devtest  accuracy_test\n",
       "15        MaxentClassifier  gender_features4             0.808          0.812\n",
       "7   DecisionTreeClassifier  gender_features2             0.788          0.798\n",
       "13        MaxentClassifier  gender_features2             0.812          0.788\n",
       "3     NaiveBayesClassifier  gender_features4             0.792          0.782\n",
       "8   DecisionTreeClassifier  gender_features3             0.760          0.780\n",
       "14        MaxentClassifier  gender_features3             0.758          0.776\n",
       "1     NaiveBayesClassifier  gender_features2             0.776          0.760\n",
       "9   DecisionTreeClassifier  gender_features4             0.754          0.742\n",
       "2     NaiveBayesClassifier  gender_features3             0.764          0.740\n",
       "12        MaxentClassifier  gender_features1             0.750          0.732\n",
       "0     NaiveBayesClassifier  gender_features1             0.750          0.732\n",
       "6   DecisionTreeClassifier  gender_features1             0.750          0.732\n",
       "10  DecisionTreeClassifier  gender_features5             0.728          0.714\n",
       "4     NaiveBayesClassifier  gender_features5             0.728          0.714\n",
       "16        MaxentClassifier  gender_features5             0.728          0.714\n",
       "11  DecisionTreeClassifier  gender_features6             0.670          0.644\n",
       "5     NaiveBayesClassifier  gender_features6             0.670          0.644\n",
       "17        MaxentClassifier  gender_features6             0.670          0.644"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = summarize_models(models)\n",
    "table.sort_values(by='accuracy_test', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest accuracy score overall was attained by a MaxEntropy classifier using gender_features4 (combining many different features) for an accuracy of 0.812.\n",
    "\n",
    "This was followed by a Decision Tree classifier using gender_features2 (first, last, and counts by letter) for an accuracy of 0.798.\n",
    "\n",
    "The top ranked Naive Bayes classifier used gender_features4 garnered fourth place with an accuracy of 0.782.\n",
    "\n",
    "Across all classifiers, gender_features1 (last letter), gender_features5 (whether first and last are vowels), and gender_features6 (length of name), respectively, performed worst. Gender_features2 (first, last, and counter by letter)\n",
    "gender_features3 (last and penultimate), gender_features4 (many features) performed differently by model, without an evident pattern.\n",
    "\n",
    "We isolated the top performing model - MaxEntropy classifier with features that include first letter, last letter, presence and counts of all letters, and suffixes (final sequence of one, two, or three letters) - as our **best_model**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ConditionalExponentialClassifier: 2 labels, 2572 features>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = models[15][0] # Select the best model by index from the table above\n",
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>accuracy_devtest</th>\n",
       "      <th>accuracy_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MaxentClassifier</td>\n",
       "      <td>0.754333</td>\n",
       "      <td>0.744333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.735000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaiveBayesClassifier</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>0.728667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    class  accuracy_devtest  accuracy_test\n",
       "1        MaxentClassifier          0.754333       0.744333\n",
       "0  DecisionTreeClassifier          0.741667       0.735000\n",
       "2    NaiveBayesClassifier          0.746667       0.728667"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.groupby('class', as_index=False).mean().sort_values(by='accuracy_test', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, assessed on the basis of average accuracy over the different feature sets, MaxEntropy outperforms Decision Tress, and both outscore Naive Bayes. \n",
    "\n",
    "This may have something to do with the MaxEntropy classifiers accounting for connections between the features rather than treating them independently in the way that Naive Bayes does; and it is also possible that the assumption of feature independence is detrimental to the relative performance of the Naive Bayes classifiers, given that we know that these features are interrelated.\n",
    "\n",
    "MaxEntropy models were relatively more accurate than Naive Bayes and Decision Tree classifiers, but that came at significant computational cost. If implementing at scale and/or in production, the accuracy gains MaxEntropy would have to be considered in light of the computational costs. Alternatively, algorithms more efficient than GIS (i.e. coordinate descent) would be worth evaluating, either using an updated NLTK package that supports recent versions of SciPy, or using a different set of packages not dependent on NLTK.\n",
    "\n",
    "While an essential tool for Natural Language Processing, the NLTK module may not contain the most powerful classifiers. Revisiting this project using the sklearn package could allow for more control over and options in the classification process. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
